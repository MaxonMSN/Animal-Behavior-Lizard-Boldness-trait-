{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "780446b5",
   "metadata": {},
   "source": [
    "# Data pre processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "888be8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# load dataset\n",
    "dataset = pd.read_csv(r'D:\\Fun projects\\Neural Network\\Datasets\\Lizard_behavior\\behavior_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "358cbf54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lizard</th>\n",
       "      <th>year</th>\n",
       "      <th>date</th>\n",
       "      <th>aggression</th>\n",
       "      <th>boldness</th>\n",
       "      <th>sex</th>\n",
       "      <th>avgmass</th>\n",
       "      <th>trialnum</th>\n",
       "      <th>assayyear</th>\n",
       "      <th>yrsinsite</th>\n",
       "      <th>avgbothNymph_Larva</th>\n",
       "      <th>avgtotal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2015</td>\n",
       "      <td>10/6/2015</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.195733</td>\n",
       "      <td>0.0</td>\n",
       "      <td>755.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2015</td>\n",
       "      <td>10/21/2015</td>\n",
       "      <td>5</td>\n",
       "      <td>-1.413857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>755.6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>7.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2015</td>\n",
       "      <td>11/4/2015</td>\n",
       "      <td>5</td>\n",
       "      <td>-1.007816</td>\n",
       "      <td>0.0</td>\n",
       "      <td>755.6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>7.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>2015</td>\n",
       "      <td>10/7/2015</td>\n",
       "      <td>2</td>\n",
       "      <td>-2.225940</td>\n",
       "      <td>1.0</td>\n",
       "      <td>705.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>2015</td>\n",
       "      <td>10/22/2015</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.601774</td>\n",
       "      <td>1.0</td>\n",
       "      <td>705.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Lizard  year        date  aggression  boldness  sex  avgmass  trialnum  \\\n",
       "0       2  2015   10/6/2015           5 -0.195733  0.0    755.6         1   \n",
       "1       2  2015  10/21/2015           5 -1.413857  0.0    755.6         2   \n",
       "2       2  2015   11/4/2015           5 -1.007816  0.0    755.6         3   \n",
       "3      13  2015   10/7/2015           2 -2.225940  1.0    705.0         1   \n",
       "4      13  2015  10/22/2015           2 -0.601774  1.0    705.0         2   \n",
       "\n",
       "   assayyear  yrsinsite  avgbothNymph_Larva  avgtotal  \n",
       "0          1          1            6.000000  8.000000  \n",
       "1          1          1            5.333333  7.333333  \n",
       "2          1          1            5.000000  7.250000  \n",
       "3          1          1            4.500000  5.000000  \n",
       "4          1          1            4.000000  4.333333  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d3b62d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1013, 12)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shape of  the dataset\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "62712d57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.038833110206211"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['avgtotal'].skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "967d934a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Majesty\\AppData\\Local\\Temp\\ipykernel_20324\\1511974118.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  dataset['boldness'].fillna(dataset['boldness'].median(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "dataset['boldness'].fillna(dataset['boldness'].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52272c3c",
   "metadata": {},
   "source": [
    "when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "11546926",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.fillna({'sex': dataset['sex'].mode()[0]}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c6a21175",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.fillna({'avgmass': dataset['avgmass'].mean()}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1764ef26",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.fillna({'avgbothNymph_Larva': dataset['avgbothNymph_Larva'].median()}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0e0b9381",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.fillna({'avgtotal': dataset['avgtotal'].median()}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bb7a0b74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lizard                0\n",
       "year                  0\n",
       "date                  0\n",
       "aggression            0\n",
       "boldness              0\n",
       "sex                   0\n",
       "avgmass               0\n",
       "trialnum              0\n",
       "assayyear             0\n",
       "yrsinsite             0\n",
       "avgbothNymph_Larva    0\n",
       "avgtotal              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d05fb76",
   "metadata": {},
   "source": [
    "use central tendenncies for boldness :184, sex : 32 ,avgbothNymph_larva:11, avgtotal: 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e7f35158",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lizard</th>\n",
       "      <th>year</th>\n",
       "      <th>date</th>\n",
       "      <th>aggression</th>\n",
       "      <th>boldness</th>\n",
       "      <th>sex</th>\n",
       "      <th>avgmass</th>\n",
       "      <th>trialnum</th>\n",
       "      <th>assayyear</th>\n",
       "      <th>yrsinsite</th>\n",
       "      <th>avgbothNymph_Larva</th>\n",
       "      <th>avgtotal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2015</td>\n",
       "      <td>10/6/2015</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.195733</td>\n",
       "      <td>0.0</td>\n",
       "      <td>755.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2015</td>\n",
       "      <td>10/21/2015</td>\n",
       "      <td>5</td>\n",
       "      <td>-1.413857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>755.6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>7.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2015</td>\n",
       "      <td>11/4/2015</td>\n",
       "      <td>5</td>\n",
       "      <td>-1.007816</td>\n",
       "      <td>0.0</td>\n",
       "      <td>755.6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>7.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>2015</td>\n",
       "      <td>10/7/2015</td>\n",
       "      <td>2</td>\n",
       "      <td>-2.225940</td>\n",
       "      <td>1.0</td>\n",
       "      <td>705.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>2015</td>\n",
       "      <td>10/22/2015</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.601774</td>\n",
       "      <td>1.0</td>\n",
       "      <td>705.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Lizard  year        date  aggression  boldness  sex  avgmass  trialnum  \\\n",
       "0       2  2015   10/6/2015           5 -0.195733  0.0    755.6         1   \n",
       "1       2  2015  10/21/2015           5 -1.413857  0.0    755.6         2   \n",
       "2       2  2015   11/4/2015           5 -1.007816  0.0    755.6         3   \n",
       "3      13  2015   10/7/2015           2 -2.225940  1.0    705.0         1   \n",
       "4      13  2015  10/22/2015           2 -0.601774  1.0    705.0         2   \n",
       "\n",
       "   assayyear  yrsinsite  avgbothNymph_Larva  avgtotal  \n",
       "0          1          1            6.000000  8.000000  \n",
       "1          1          1            5.333333  7.333333  \n",
       "2          1          1            5.000000  7.250000  \n",
       "3          1          1            4.500000  5.000000  \n",
       "4          1          1            4.000000  4.333333  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "48941202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download new csv\n",
    "dataset.to_csv('Clean_Lizard_behave.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22eef50a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b3743b6b",
   "metadata": {},
   "source": [
    "# Dataset cleaned \n",
    "Now forward to ML training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248e86ab",
   "metadata": {},
   "source": [
    "# Predicting Future Boldness in Lizards Using LSTM (Deep Learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed0e64e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f392cad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = pd.read_csv(r'D:\\Fun projects\\Neural Network\\Datasets\\Lizard_behavior\\Clean_Lizard_behave.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c82c6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a430f17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8cd3a12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lizard</th>\n",
       "      <th>year</th>\n",
       "      <th>date</th>\n",
       "      <th>aggression</th>\n",
       "      <th>boldness</th>\n",
       "      <th>sex</th>\n",
       "      <th>avgmass</th>\n",
       "      <th>trialnum</th>\n",
       "      <th>assayyear</th>\n",
       "      <th>yrsinsite</th>\n",
       "      <th>avgbothNymph_Larva</th>\n",
       "      <th>avgtotal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2015</td>\n",
       "      <td>10/6/2015</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.195733</td>\n",
       "      <td>0.0</td>\n",
       "      <td>755.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2015</td>\n",
       "      <td>10/21/2015</td>\n",
       "      <td>5</td>\n",
       "      <td>-1.413857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>755.6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>7.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2015</td>\n",
       "      <td>11/4/2015</td>\n",
       "      <td>5</td>\n",
       "      <td>-1.007816</td>\n",
       "      <td>0.0</td>\n",
       "      <td>755.6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>7.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>2015</td>\n",
       "      <td>10/7/2015</td>\n",
       "      <td>2</td>\n",
       "      <td>-2.225940</td>\n",
       "      <td>1.0</td>\n",
       "      <td>705.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>2015</td>\n",
       "      <td>10/22/2015</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.601774</td>\n",
       "      <td>1.0</td>\n",
       "      <td>705.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Lizard  year        date  aggression  boldness  sex  avgmass  trialnum  \\\n",
       "0       2  2015   10/6/2015           5 -0.195733  0.0    755.6         1   \n",
       "1       2  2015  10/21/2015           5 -1.413857  0.0    755.6         2   \n",
       "2       2  2015   11/4/2015           5 -1.007816  0.0    755.6         3   \n",
       "3      13  2015   10/7/2015           2 -2.225940  1.0    705.0         1   \n",
       "4      13  2015  10/22/2015           2 -0.601774  1.0    705.0         2   \n",
       "\n",
       "   assayyear  yrsinsite  avgbothNymph_Larva  avgtotal  \n",
       "0          1          1            6.000000  8.000000  \n",
       "1          1          1            5.333333  7.333333  \n",
       "2          1          1            5.000000  7.250000  \n",
       "3          1          1            4.500000  5.000000  \n",
       "4          1          1            4.000000  4.333333  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a85b40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convt values to date and time\n",
    "'''dat['date'] = pd.to_datetime(dat['date'])\n",
    "\n",
    "# Sorted date and time\n",
    "dat2 = dat.sort_values(by = 'date')\n",
    "\n",
    "# Download new csv\n",
    "dat2.to_csv('date_Lizard_behave.csv', index=False)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1855561a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import io # Use io only when data is in a python string like  \" 1, 2, 3, \"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d9703928",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat['date'] = pd.to_datetime(dat['date'])\n",
    "dat= dat.sort_values(by = ['Lizard','date']).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9987b0dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lizard</th>\n",
       "      <th>year</th>\n",
       "      <th>date</th>\n",
       "      <th>aggression</th>\n",
       "      <th>boldness</th>\n",
       "      <th>sex</th>\n",
       "      <th>avgmass</th>\n",
       "      <th>trialnum</th>\n",
       "      <th>assayyear</th>\n",
       "      <th>yrsinsite</th>\n",
       "      <th>avgbothNymph_Larva</th>\n",
       "      <th>avgtotal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2015</td>\n",
       "      <td>2015-10-06</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.195733</td>\n",
       "      <td>0.0</td>\n",
       "      <td>755.600000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2015</td>\n",
       "      <td>2015-10-21</td>\n",
       "      <td>5</td>\n",
       "      <td>-1.413857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>755.600000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>7.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2015</td>\n",
       "      <td>2015-11-04</td>\n",
       "      <td>5</td>\n",
       "      <td>-1.007816</td>\n",
       "      <td>0.0</td>\n",
       "      <td>755.600000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>7.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>2015</td>\n",
       "      <td>2015-10-07</td>\n",
       "      <td>2</td>\n",
       "      <td>-2.225940</td>\n",
       "      <td>1.0</td>\n",
       "      <td>705.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>2015</td>\n",
       "      <td>2015-10-22</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.601774</td>\n",
       "      <td>1.0</td>\n",
       "      <td>705.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>10000008</td>\n",
       "      <td>2011</td>\n",
       "      <td>2011-10-24</td>\n",
       "      <td>2</td>\n",
       "      <td>0.067909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>714.630113</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>3.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>10000008</td>\n",
       "      <td>2011</td>\n",
       "      <td>2011-11-19</td>\n",
       "      <td>1</td>\n",
       "      <td>0.067909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>714.630113</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>3.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010</th>\n",
       "      <td>10000009</td>\n",
       "      <td>2011</td>\n",
       "      <td>2011-10-02</td>\n",
       "      <td>11</td>\n",
       "      <td>0.067909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>714.630113</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>3.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>10000009</td>\n",
       "      <td>2011</td>\n",
       "      <td>2011-10-25</td>\n",
       "      <td>5</td>\n",
       "      <td>0.067909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>714.630113</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>3.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012</th>\n",
       "      <td>10000009</td>\n",
       "      <td>2011</td>\n",
       "      <td>2011-11-17</td>\n",
       "      <td>5</td>\n",
       "      <td>0.067909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>714.630113</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>3.400000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1013 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Lizard  year       date  aggression  boldness  sex     avgmass  \\\n",
       "0            2  2015 2015-10-06           5 -0.195733  0.0  755.600000   \n",
       "1            2  2015 2015-10-21           5 -1.413857  0.0  755.600000   \n",
       "2            2  2015 2015-11-04           5 -1.007816  0.0  755.600000   \n",
       "3           13  2015 2015-10-07           2 -2.225940  1.0  705.000000   \n",
       "4           13  2015 2015-10-22           2 -0.601774  1.0  705.000000   \n",
       "...        ...   ...        ...         ...       ...  ...         ...   \n",
       "1008  10000008  2011 2011-10-24           2  0.067909  0.0  714.630113   \n",
       "1009  10000008  2011 2011-11-19           1  0.067909  0.0  714.630113   \n",
       "1010  10000009  2011 2011-10-02          11  0.067909  0.0  714.630113   \n",
       "1011  10000009  2011 2011-10-25           5  0.067909  0.0  714.630113   \n",
       "1012  10000009  2011 2011-11-17           5  0.067909  0.0  714.630113   \n",
       "\n",
       "      trialnum  assayyear  yrsinsite  avgbothNymph_Larva  avgtotal  \n",
       "0            1          1          1            6.000000  8.000000  \n",
       "1            2          1          1            5.333333  7.333333  \n",
       "2            3          1          1            5.000000  7.250000  \n",
       "3            1          1          1            4.500000  5.000000  \n",
       "4            2          1          1            4.000000  4.333333  \n",
       "...        ...        ...        ...                 ...       ...  \n",
       "1008         2          1          1            0.750000  3.400000  \n",
       "1009         3          1          1            0.750000  3.400000  \n",
       "1010         1          1          1            0.750000  3.400000  \n",
       "1011         2          1          1            0.750000  3.400000  \n",
       "1012         3          1          1            0.750000  3.400000  \n",
       "\n",
       "[1013 rows x 12 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3aa27df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering\n",
    "Target = 'boldness'\n",
    "Features = [\n",
    "    'aggression','sex','avgmass','trialnum',\n",
    "    'assayyear', 'yrsinsite','avgbothNymph_Larva',\n",
    "    'avgtotal', 'boldness'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ad430455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale features for better model performance\n",
    "scaler = StandardScaler()\n",
    "dat[Features] = scaler.fit_transform(dat[Features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a5bf9597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequences for lizard\n",
    "sequences = []\n",
    "# Past sequence to remember\n",
    "sequence_length = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ee0150",
   "metadata": {},
   "source": [
    "✅ What is .iloc?\n",
    ".iloc means: \"index location\"\n",
    "It is used in Pandas to access rows by number (like 0th, 1st, 2nd row, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7574d943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iloc ex : df.iloc[2:5]  # gives you rows 2, 3, and 4\n",
    "\n",
    "# Grouping lizard\n",
    "for lizard_id, group in dat.groupby('Lizard'):\n",
    "    if len(group) > sequence_length:\n",
    "        for i in range(len(group) - sequence_length):\n",
    "            # Input sequence (X)\n",
    "            seq = group[Features].iloc[i:i+sequence_length].values\n",
    "            # The target value (Y)\n",
    "            target = group[Target].iloc[i + sequence_length]\n",
    "            sequences.append((seq, target))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7cc08860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the sequence into train and test sets\n",
    "train_sequences , test_sequences = train_test_split(sequences, test_size = 0.2, random_state =42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "213a2e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LizardDataset(Dataset):\n",
    "    def __init__(self, sequences):\n",
    "        self.sequences = sequences\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sequence, target = self.sequences[idx]\n",
    "        return torch.tensor(sequence, dtype = torch.float32), torch.tensor(target, dtype = torch.float32)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "90aff65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "train_dataset  =LizardDataset(train_sequences)\n",
    "test_dataset = LizardDataset(test_sequences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6034d1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader\n",
    "train_loader = DataLoader(train_dataset, batch_size = 4, shuffle = True)\n",
    "test_loader = DataLoader(test_dataset, batch_size = 4, shuffle = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "28351dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- LSTM Model ----\n",
    "\n",
    "class BoldnessPredictor(nn.Module):\n",
    "    def __init__(self, n_features, hidden_units):\n",
    "        super().__init__()\n",
    "        self.n_features = n_features\n",
    "        self.hidden_units = hidden_units\n",
    "        \n",
    "        # LSTM layer\n",
    "        self.LSTM = nn.LSTM(\n",
    "            input_size = n_features,\n",
    "            hidden_size = hidden_units,\n",
    "            num_layers = 4,\n",
    "            batch_first =True,\n",
    "            dropout = 0.2\n",
    "        )\n",
    "        # Fully connected (fc) Output layer\n",
    "        self.linear = nn.Linear(in_features = hidden_units, out_features = 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # The LSTM returns the output and the final hidden/cell states\n",
    "        LSTM_out, (h_n, c_n) = self.LSTM(x)\n",
    "        \n",
    "        # We only want the output from the very last time step\n",
    "        last_time_step_out = LSTM_out[:, -1 ,:]\n",
    "        \n",
    "        # Pass the last output to our linear layer to get the prediction\n",
    "        y_pred = self.linear(last_time_step_out)\n",
    "        return y_pred\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a027bbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---Training the model ---\n",
    "\n",
    "# hyperparameters\n",
    "n_features = len(Features)\n",
    "hidden_units = 50\n",
    "lr = 0.001\n",
    "epochs =100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2aecc66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model initiation\n",
    "model = BoldnessPredictor(n_features = n_features, hidden_units=hidden_units)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ade5b2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss_fun\n",
    "loss_function = nn.MSELoss() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a11b88c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b29d6d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Majesty\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\loss.py:608: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100, loss: 0.6126\n",
      "Epoch 20/100, loss: 0.5139\n",
      "Epoch 30/100, loss: 0.4393\n",
      "Epoch 40/100, loss: 0.3652\n",
      "Epoch 50/100, loss: 0.3199\n",
      "Epoch 60/100, loss: 0.2539\n",
      "Epoch 70/100, loss: 0.1991\n",
      "Epoch 80/100, loss: 0.1408\n",
      "Epoch 90/100, loss: 0.1167\n",
      "Epoch 100/100, loss: 0.0990\n",
      "Training completed\n"
     ]
    }
   ],
   "source": [
    "print(\"Start training\")\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for seq, target in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        y_pred = model(seq).squeeze() # to remove extra dimensions\n",
    "        \n",
    "        # Calc loss\n",
    "        loss = loss_function(y_pred, target)\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    avg_loss = total_loss/ len(train_loader)\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, loss: {avg_loss:.4f}\")\n",
    "\n",
    "print(\"Training completed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "738924d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluation Results ---\n",
      "Predicted Boldness: 0.0404, Actual Boldness: 0.0263\n",
      "Predicted Boldness: -1.4145, Actual Boldness: -0.2051\n",
      "Predicted Boldness: -1.3247, Actual Boldness: 1.2929\n",
      "Predicted Boldness: -0.0132, Actual Boldness: -0.5644\n",
      "Predicted Boldness: -0.4371, Actual Boldness: -0.2051\n",
      "\n",
      "Root Mean Squared Error (RMSE) on Test Set: 1.0310\n"
     ]
    }
   ],
   "source": [
    "# --- 6. Evaluating the Model (Corrected) ---\n",
    "\n",
    "model.eval() # Set model to evaluation mode\n",
    "all_preds = []\n",
    "all_targets = []\n",
    "\n",
    "with torch.no_grad(): # We don't need to calculate gradients for evaluation\n",
    "    for seq, target in test_loader:\n",
    "        y_pred = model(seq).squeeze()\n",
    "        \n",
    "        # --- THIS IS THE FIX ---\n",
    "        # Handle the case where the batch size is 1 and squeeze() creates a scalar\n",
    "        if y_pred.dim() == 0:\n",
    "            all_preds.append(y_pred.item())\n",
    "        else:\n",
    "            all_preds.extend(y_pred.tolist())\n",
    "        \n",
    "        if target.dim() == 0:\n",
    "            all_targets.append(target.item())\n",
    "        else:\n",
    "            all_targets.extend(target.tolist())\n",
    "        # --- END OF FIX ---\n",
    "\n",
    "\n",
    "# Un-scale the predictions and targets to see the real values\n",
    "# Note: The target was also part of the scaled features, so we need a dummy array to inverse transform\n",
    "dummy_array_preds = np.zeros((len(all_preds), len(Features)))\n",
    "dummy_array_preds[:, -1] = all_preds # Put predictions in the 'boldness' column\n",
    "unscaled_preds = scaler.inverse_transform(dummy_array_preds)[:, -1]\n",
    "\n",
    "dummy_array_targets = np.zeros((len(all_targets), len(Features)))\n",
    "dummy_array_targets[:, -1] = all_targets\n",
    "unscaled_targets = scaler.inverse_transform(dummy_array_targets)[:, -1]\n",
    "\n",
    "\n",
    "# Print some example predictions\n",
    "print(\"\\n--- Evaluation Results ---\")\n",
    "for i in range(min(5, len(unscaled_preds))):\n",
    "    print(f\"Predicted Boldness: {unscaled_preds[i]:.4f}, Actual Boldness: {unscaled_targets[i]:.4f}\")\n",
    "\n",
    "# Calculate final error metric (e.g., Root Mean Squared Error)\n",
    "rmse = np.sqrt(np.mean((unscaled_preds - unscaled_targets)**2))\n",
    "print(f\"\\nRoot Mean Squared Error (RMSE) on Test Set: {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7f4a4781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "torch.save(model, 'lizard model boldness.pth')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
